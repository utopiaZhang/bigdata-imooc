#source+channel+sink的名字
agent.sources = kafkaSource
agent.channels = kafka2Hdfs
agent.sinks = hdfsSink

# 指定source使用的channel名字
agent.sources.kafkaSource.channels = kafka2Hdfs
# 指定sink需要使用的channel的名字
agent.sinks.hdfsSink.channel = kafka2Hdfs


#-------- kafkaSource相关配置-----------------
# 定义消息源类型
agent.sources.kafkaSource.type = org.apache.flume.source.kafka.KafkaSource
# 定义kafka所在zk的地址
agent.sources.kafkaSource.kafka.bootstrap.servers = bigdata01:9092,bigdata02:9092,bigdata03:9092
# 配置消费的kafka topic
agent.sources.kafkaSource.kafka.topics = video_info
# 配置消费者组的id
agent.sources.kafkaSource.kafka.consumer.group.id = video_info_con_1




#------- fileChannel-1相关配置-------------------------
# channel类型
agent.channels.kafka2Hdfs.type = file
agent.channels.kafka2Hdfs.checkpointDir = /data/filechannle_data/video_info/checkpoint
agent.channels.kafka2Hdfs.dataDirs = /data/filechannle_data/video_info/data




#---------hdfsSink 相关配置------------------
agent.sinks.hdfsSink.type = hdfs
# 注意, 我们输出到下面一个子文件夹datax中
agent.sinks.hdfsSink.hdfs.path = hdfs://bigdata01:9000/data/video_info/%Y%m%d
agent.sinks.hdfsSink.hdfs.writeFormat = Text
agent.sinks.hdfsSink.hdfs.fileType = DataStream
agent.sinks.hdfsSink.hdfs.callTimeout = 3600000

#当文件大小为104857600字节时，将临时文件滚动成一个目标文件
agent.sinks.hdfsSink.hdfs.rollSize = 104857600
#events数据达到该数量的时候，将临时文件滚动成目标文件
agent.sinks.hdfsSink.hdfs.rollCount = 0
#每隔N s将临时文件滚动成一个目标文件
agent.sinks.hdfsSink.hdfs.rollInterval = 3600

#配置前缀和后缀
agent.sinks.hdfsSink.hdfs.filePrefix=run
agent.sinks.hdfsSink.hdfs.fileSuffix=.data