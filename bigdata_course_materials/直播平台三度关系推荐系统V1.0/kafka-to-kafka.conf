#source+channle+sink的名字
agent.sources = kafkaSource
agent.channels = fileChannl
agent.sinks = kafkaSink

# 指定source使用的channel
agent.sources.kafkaSource.channels = fileChannl
# 指定sink需要使用的channel的
agent.sinks.kafkaSink.channel = fileChannl


#-------- kafkaSource相关配置-----------------
agent.sources.kafkaSource.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.kafkaSource.batchSize = 1000
agent.sources.kafkaSource.batchDurationMillis = 1000
agent.sources.kafkaSource.kafka.bootstrap.servers = bigdata01:9092,bigdata02:9092,bigdata03:9092
agent.sources.kafkaSource.kafka.topics = all_type_data_r2p40
agent.sources.kafkaSource.kafka.consumer.group.id = flume_con_id_1
#----------------- 拦截器 -------------------
# 定义拦截器
agent.sources.kafkaSource.interceptors = i2 i1
# 设置拦截器类型
agent.sources.kafkaSource.interceptors.i1.type = regex_extractor
# 设置正则表达式，匹配指定的数据，这样设置会在数据的header中增加topic=aaa
agent.sources.kafkaSource.interceptors.i1.regex = "type":"(\\w+)"
agent.sources.kafkaSource.interceptors.i1.serializers = s1
agent.sources.kafkaSource.interceptors.i1.serializers.s1.name = topic
# 避免遇到数据中没有type字段的，给这些数据赋一个默认topic【注意：这个拦截器必须设置】
agent.sources.kafkaSource.interceptors.i2.type = static
agent.sources.kafkaSource.interceptors.i2.key = topic
agent.sources.kafkaSource.interceptors.i2.preserveExisting = false
agent.sources.kafkaSource.interceptors.i2.value = default_r2p5
#------- fileChannel相关配置-------------------------
# channel类型
agent.channels.fileChannl.type = file
agent.channels.fileChannl.checkpointDir = /data/filechannle_data/all_type_data/checkpoint
agent.channels.kafka2HdfsShow.dataDirs = /data/filechannle_data/all_type_data/data
#---------kafkaSink 相关配置------------------
agent.sinks.kafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
agent.sinks.kafkaSink.kafka.topic = default
agent.sinks.kafkaSink.kafka.bootstrap.servers = bigdata01:9092,bigdata02:9092,bigdata03:9092
agent.sinks.kafkaSink.kafka.flumeBatchSize = 1
agent.sinks.kafkaSink.kafka.producer.acks = 1
agent.sinks.kafkaSink.kafka.producer.linger.ms = 1
agent.sinks.kafkaSink.kafka.producer.compression.type = snappy